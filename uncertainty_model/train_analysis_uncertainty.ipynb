{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Input:\n",
    "\"$RD$\": Relative density \n",
    "\"$\\alpha_{x}$\": Rotation angles about the x-axis\n",
    "\"$\\alpha_{y}$\": Rotation angles about the y-axis\n",
    "\"$\\alpha_{z}$\": Rotation angles about the z-axis\n",
    "\"$E$\": Elastic modulus\n",
    "\"$\\nu$\": Poisson's ratio\n",
    "\"$\\rho$\": Mass density\n",
    "# Output:\n",
    "\"$w_{c}^{S}$\": Central deflection of simply supported plate\n",
    "\"$w_{c}^{C}$\": Central deflection of fully clamped plate\n",
    "\"$\\dfrac{\\omega_{1}^{S}}{2\\pi}$\": First natural frequency of simply supported plate\n",
    "\"$\\dfrac{\\omega_{2}^{S}}{2\\pi}$\": Second natural frequency of simply supported plate\n",
    "\"$\\dfrac{\\omega_{1}^{C}}{2\\pi}$\": First natural frequency of fully clamped plate\n",
    "\"$\\dfrac{\\omega_{2}^{C}}{2\\pi}$\": Second natural frequency of fully clamped plate"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "89929f7015cf5f17"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d28156f6-7351-40f5-bd70-90b6b6bb8c0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T13:46:09.349306Z",
     "start_time": "2024-06-12T13:46:09.346776Z"
    }
   },
   "outputs": [],
   "source": [
    "import os,sys\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = '1'\n",
    "os.environ['MKL_NUM_THREADS']      = '1'\n",
    "os.environ['OMP_NUM_THREADS']      = '1'\n",
    "sys.path.append('..')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from BNN_pSGLD import BNN_pSGLD_Method\n",
    "from torchmetrics.functional.regression import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def metric_evaluate(py, test_y):\n",
    "    err  = py - test_y\n",
    "    mse  = torch.mean(err**2, dim = 0)\n",
    "    rmse = mse.sqrt()\n",
    "    y_mean = train_y.mean(dim = 0)\n",
    "    smse = mse / torch.mean((test_y - y_mean)**2, dim = 0)\n",
    "    r2 = r2_score(py, test_y, multioutput='raw_values')\n",
    "    mape = torch.mean((np.abs((py - test_y) / test_y)),  dim=0) * 100\n",
    "    mean_mape = mape.mean()\n",
    "    return rmse, smse, r2, mape, mean_mape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T13:46:10.312926Z",
     "start_time": "2024-06-12T13:46:10.310105Z"
    }
   },
   "id": "3c5486d1192c2f58",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df = pd.read_excel('datasets/BNN_data_combine.xlsx')\n",
    "df = df.drop(['ID', 'Name', 'Input_1', 'Input_2', 'Input_3', 'Input_4'], axis=1)\n",
    "\n",
    "df = df.sample(frac=1,random_state=12).reset_index(drop=True)\n",
    "no_train = int(len(df)*0.8)\n",
    "df_train = df[:no_train]\n",
    "df_test = df[no_train:]\n",
    "\n",
    "trainX = df_train[['Input_5', 'Input_6', 'Input_7', 'Input_8', 'Input_9_1', 'Input_9_2', 'Input_9_3']]\n",
    "trainY = df_train[['Output_1', 'Output_2', 'Output_3', 'Output_4', 'Output_5', 'Output_6']]\n",
    "testX = df_test[['Input_5', 'Input_6', 'Input_7', 'Input_8', 'Input_9_1', 'Input_9_2', 'Input_9_3']]\n",
    "testY = df_test[['Output_1', 'Output_2', 'Output_3', 'Output_4', 'Output_5', 'Output_6']]\n",
    "\n",
    "train_x = torch.FloatTensor(np.array(trainX))\n",
    "train_y = torch.FloatTensor(np.array(trainY))\n",
    "test_x  = torch.FloatTensor(np.array(testX))\n",
    "test_y  = torch.FloatTensor(np.array(testY))\n",
    "\n",
    "torch.save(test_x, 'results/test_x.pt')\n",
    "\n",
    "print(\"Number of training data: %d\" % train_x.shape[0])\n",
    "print(\"Number of testing data: %d\" % test_x.shape[0])\n",
    "print(\"Dimension: %d\" % train_x.shape[1])\n",
    "print(\"Output: %d\" % train_y.shape[1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-21T06:40:53.181906Z",
     "start_time": "2024-06-21T06:40:53.179617Z"
    }
   },
   "id": "8dfc5fdd32b73835",
   "execution_count": 409
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "7575143f-410b-4ae1-9e36-cb82c9626af1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T06:40:59.065554Z",
     "start_time": "2024-06-21T06:40:59.063423Z"
    }
   },
   "outputs": [],
   "source": [
    "x_mean = train_x.mean(dim = 0)\n",
    "x_std  = train_x.std(dim = 0)\n",
    "y_mean = train_y.mean(dim = 0)\n",
    "y_std  = train_y.std(dim = 0)\n",
    "\n",
    "train_x = (train_x - x_mean) / x_std\n",
    "train_y = (train_y - y_mean) / y_std\n",
    "test_x  = (test_x - x_mean)  / x_std\n",
    "\n",
    "conf                 = {}\n",
    "conf['noise_level']  = 0.00001\n",
    "conf['steps_burnin'] = 200\n",
    "conf['steps']        = 10000\n",
    "conf['keep_every']   = 50\n",
    "conf['lr_weight']    = 1e-3\n",
    "conf['lr_noise']     = 1e-3\n",
    "\n",
    "lst_hiddens = [512, 512, 512, 512, 512,512]\n",
    "\n",
    "model = BNN_pSGLD_Method(dim = train_x.shape[1], nout = train_y.shape[1], act = nn.ReLU(), num_hiddens = lst_hiddens, conf = conf)\n",
    "model.train(train_x, train_y)\n",
    "model.report()"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    pred = model.sample_predict(model.nns, test_x)  * y_std + y_mean\n",
    "\n",
    "py = pred.mean(dim = 0)\n",
    "ps = pred.std(dim = 0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-14T13:08:57.859600Z",
     "start_time": "2024-06-14T13:08:55.777890Z"
    }
   },
   "id": "aa2f70b6ff4fd78b",
   "execution_count": 310
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "metric_evaluate(py, test_y)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-21T06:40:43.856160Z",
     "start_time": "2024-06-21T06:40:43.853881Z"
    }
   },
   "id": "e257046a4695d519",
   "execution_count": 409
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# torch.save(pred.mean(dim = 0), 'results/predict_mean.pt')\n",
    "# torch.save(pred, 'results/predict.pt')\n",
    "# torch.save(ps, 'results/predict_std.pt')\n",
    "# torch.save(test_y, 'results/test_y.pt')\n",
    "\n",
    "py = torch.load('results/predict_mean.pt')\n",
    "pred = torch.load('results/predict.pt')\n",
    "ps = torch.load('results/predict_std.pt')\n",
    "test_y = torch.load('results/test_y.pt')\n",
    "test_x = torch.load('results/test_x.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-13T19:32:55.927360Z",
     "start_time": "2024-06-13T19:32:55.903934Z"
    }
   },
   "id": "215b2ed207ba89c4",
   "execution_count": 62
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluate the correlation of rotation angles"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "154a038e5103d863"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_test_corr_rotation = pd.read_excel('datasets/test_corr_rotation.xlsx')\n",
    "\n",
    "testX_rotation = df_test_corr_rotation[['Input_5', 'Input_6', 'Input_7', 'Input_8', 'Input_9_1', 'Input_9_2', 'Input_9_3']]\n",
    "test_x_rotation = torch.FloatTensor(np.array(testX_rotation))\n",
    "\n",
    "test_x_rotation  = (test_x_rotation - x_mean) / x_std\n",
    "\n",
    "with torch.no_grad():\n",
    "    analysis_corr_rotation = model.sample_predict(model.nns, test_x_rotation)  * y_std + y_mean\n",
    "    \n",
    "predict_analysis_corr_rotation = analysis_corr_rotation.mean(dim = 0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-10T18:10:22.364352Z",
     "start_time": "2024-06-10T18:10:19.711332Z"
    }
   },
   "id": "92f9674d50f60591",
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_test_corr_rotation['Output_1'] = predict_analysis_corr_rotation[:,0]\n",
    "df_test_corr_rotation['Output_2'] = predict_analysis_corr_rotation[:,1]\n",
    "df_test_corr_rotation['Output_3'] = predict_analysis_corr_rotation[:,2]\n",
    "df_test_corr_rotation['Output_4'] = predict_analysis_corr_rotation[:,3]\n",
    "df_test_corr_rotation['Output_5'] = predict_analysis_corr_rotation[:,4]\n",
    "df_test_corr_rotation['Output_6'] = predict_analysis_corr_rotation[:,5]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-21T06:43:42.425558Z",
     "start_time": "2024-06-21T06:43:42.422470Z"
    }
   },
   "id": "82f205d1c1214a74",
   "execution_count": 410
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_test_corr_rotation.to_excel('datasets/predict_check_corr_rotation.xlsx', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-10T18:10:27.298509Z",
     "start_time": "2024-06-10T18:10:26.615938Z"
    }
   },
   "id": "ec6260f08195bf57",
   "execution_count": 44
  },
  {
   "cell_type": "markdown",
   "source": [
    "# An illustrative example"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e391a467c1d4ee56"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "ground_truth_values_O1 = [float(s[0].detach()) for s in test_y]\n",
    "ground_truth_values_O2 = [float(s[1].detach()) for s in test_y]\n",
    "ground_truth_values_O3 = [float(s[2].detach()) for s in test_y]\n",
    "ground_truth_values_O4 = [float(s[3].detach()) for s in test_y]\n",
    "ground_truth_values_O5 = [float(s[4].detach()) for s in test_y]\n",
    "ground_truth_values_O6 = [float(s[5].detach()) for s in test_y]\n",
    "\n",
    "confidence_interval_O1 = [[float(s[i][0].detach()) for s in pred] for i in range(pred.shape[1])]\n",
    "confidence_interval_O2 = [[float(s[i][1].detach()) for s in pred] for i in range(pred.shape[1])]\n",
    "confidence_interval_O3 = [[float(s[i][2].detach()) for s in pred] for i in range(pred.shape[1])]\n",
    "confidence_interval_O4 = [[float(s[i][3].detach()) for s in pred] for i in range(pred.shape[1])]\n",
    "confidence_interval_O5 = [[float(s[i][4].detach()) for s in pred] for i in range(pred.shape[1])]\n",
    "confidence_interval_O6 = [[float(s[i][5].detach()) for s in pred] for i in range(pred.shape[1])]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-15T20:14:07.208174Z",
     "start_time": "2024-06-15T20:14:00.284264Z"
    }
   },
   "id": "344a0195-9aa7-4cc2-8372-715be4a941a1",
   "execution_count": 356
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# paper: 1299\n",
    "index_sample_test = 1299\n",
    "\n",
    "point_O1 = confidence_interval_O1[index_sample_test]\n",
    "point_O2 = confidence_interval_O2[index_sample_test]\n",
    "point_O3 = confidence_interval_O3[index_sample_test]\n",
    "point_O4 = confidence_interval_O4[index_sample_test]\n",
    "point_O5 = confidence_interval_O5[index_sample_test]\n",
    "point_O6 = confidence_interval_O6[index_sample_test]\n",
    "\n",
    "GT1 = ground_truth_values_O1[index_sample_test]\n",
    "GT2 = ground_truth_values_O2[index_sample_test]\n",
    "GT3 = ground_truth_values_O3[index_sample_test]\n",
    "GT4 = ground_truth_values_O4[index_sample_test]\n",
    "GT5 = ground_truth_values_O5[index_sample_test]\n",
    "GT6 = ground_truth_values_O6[index_sample_test]\n",
    "\n",
    "list_output = [point_O1,point_O2,point_O3,point_O4,point_O5,point_O6]\n",
    "list_ground_truth_values = [GT1, GT2, GT3, GT4, GT5, GT6]\n",
    "index_no = 1\n",
    "\n",
    "for predictions, ground_truth_value in zip(list_output, list_ground_truth_values):\n",
    "    predictions = np.asarray(predictions, dtype=np.float64)\n",
    "    ground_truth_value = float(ground_truth_value)\n",
    "    mean_prediction = np.mean(predictions)\n",
    "    median_prediction = np.median(predictions)\n",
    "    confidence_interval = np.percentile(predictions, [2.5, 97.5])\n",
    "    \n",
    "    # Plotting\n",
    "    fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    kde = sns.kdeplot(predictions, fill=True, color=\"skyblue\", ax=ax1)\n",
    "    \n",
    "    # Add vertical lines for mean of predict and actual value\n",
    "    ax1.axvline(mean_prediction, color='fuchsia', linestyle='dashed', linewidth=2, label=f'Predicted mean: {mean_prediction:.2f}')\n",
    "    ax1.axvline(ground_truth_value, color='orange', linestyle='dashed', linewidth=2, label=f'Actual value: {ground_truth_value:.2f}')\n",
    "    ax1.axvline(confidence_interval[0], color='limegreen', linestyle='dashed', linewidth=2, label=f'2.5\\% Percentile: {confidence_interval[0]:.2f}')\n",
    "    ax1.axvline(confidence_interval[1], color='darkcyan', linestyle='dashed', linewidth=2, label=f'97.5\\% Percentile: {confidence_interval[1]:.2f}')\n",
    "    \n",
    "    # Compute and plot CDF line\n",
    "    sorted_predictions = np.sort(predictions)\n",
    "    cumulative_prob = np.arange(1, len(sorted_predictions) + 1) / len(sorted_predictions)\n",
    "   \n",
    "    # Find the y-values for the mean prediction on the CDF and PDF\n",
    "    cdf_ground_truth = np.interp(ground_truth_value, sorted_predictions, cumulative_prob)\n",
    "    cdf_y_predict = np.interp(mean_prediction, sorted_predictions, cumulative_prob)\n",
    "    \n",
    "    ax2 = ax1.twinx()\n",
    "    # Plot horizontal lines\n",
    "    ax2.axhline(cdf_y_predict, color='fuchsia', linestyle='dotted', linewidth=2, label=f'CDF (predicted mean): {cdf_y_predict:.2f}')\n",
    "    \n",
    "    ax2.axhline(cdf_ground_truth, color='orange', linestyle='dotted', linewidth=2, label=f'CDF (actual value): {cdf_ground_truth:.2f}')\n",
    "    \n",
    "    ax2.plot(sorted_predictions, cumulative_prob, label=f'CDF', color='red', linewidth=1.5)\n",
    "    \n",
    "    # Labels and legend\n",
    "    ax1.set_xlabel('Values')\n",
    "    ax1.set_ylabel('Density', color='b',fontsize=14)\n",
    "    ax1.tick_params('y', colors='b', labelsize=14)\n",
    "\n",
    "    ax2.tick_params('y', colors='r',labelsize=14)\n",
    "    ax2.set_ylabel('Cumulative Probability', color='r',fontsize=14)\n",
    "    ax2.tick_params('y', colors='r')\n",
    "    fig.legend(loc=\"upper left\", bbox_to_anchor=(0,1), bbox_transform=ax1.transAxes,fontsize=10)\n",
    "    plt.savefig(f'results/sample_1_pdf_Output_{index_no}_sample.png')\n",
    "    index_no += 1\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-21T06:48:19.210967Z",
     "start_time": "2024-06-21T06:48:19.209407Z"
    }
   },
   "id": "21f64a66cf25ff29",
   "execution_count": 412
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluation of the BNN-pSGLD model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "915277643e509dc"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import uncertainty_toolbox as uct\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Set plot style\n",
    "uct.viz.set_style() \n",
    "uct.viz.update_rc(\"text.usetex\", True)  # Set to True for system latex\n",
    "uct.viz.update_rc(\"font.size\", 14)  # Set font size\n",
    "uct.viz.update_rc(\"xtick.labelsize\", 14)  # Set font size for xaxis tick labels\n",
    "uct.viz.update_rc(\"ytick.labelsize\", 14)  # Set font size for yaxis tick labels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-16T08:01:06.253979Z",
     "start_time": "2024-06-16T08:01:06.249592Z"
    }
   },
   "id": "f04b71b120f7be90",
   "execution_count": 379
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "py = torch.load('results/predict_mean.pt')\n",
    "pred = torch.load('results/predict.pt')\n",
    "ps = torch.load('results/predict_std.pt')\n",
    "test_y = torch.load('results/test_y.pt')\n",
    "test_x = torch.load('results/test_x.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-16T08:01:06.595806Z",
     "start_time": "2024-06-16T08:01:06.571550Z"
    }
   },
   "id": "8fb34a8938d3a3a4",
   "execution_count": 380
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "_, __, ___, x = uct.synthetic_sine_heteroscedastic(test_x.shape[0])\n",
    "\n",
    "py = pred.mean(dim = 0)\n",
    "ps = pred.std(dim = 0)\n",
    "metric_evaluate(py, test_y)\n",
    "confidence_interval=0.95\n",
    "\n",
    "\n",
    "v_MACE = []\n",
    "v_RMSCE = []\n",
    "v_MA = []\n",
    "\n",
    "for n0 in range(0,7):\n",
    "    f = py[:, n0].numpy()\n",
    "    y = test_y[:, n0].numpy()\n",
    "    std = ps[:, n0].numpy()\n",
    "    sorted_indices = np.argsort(f)\n",
    "    f = f[sorted_indices]\n",
    "    std = std[sorted_indices]\n",
    "    y = y[sorted_indices]\n",
    "    b = [min(y), max(y), min(f), max(f)]\n",
    "    # List of predictive means and standard deviations\n",
    "    pred_mean_list = [f]\n",
    "    pred_std_list = [\n",
    "        std * 0.5,  # overconfident\n",
    "        std * 1.5,  # underconfident\n",
    "        std,  # correct\n",
    "    ]\n",
    "    # Loop through, make plots, and compute metrics\n",
    "    idx_counter = 0\n",
    "    for i, pred_mean in enumerate(pred_mean_list):\n",
    "        for j, pred_std in enumerate(pred_std_list):\n",
    "            mace = uct.mean_absolute_calibration_error(pred_mean, pred_std, y)\n",
    "            rmsce = uct.root_mean_squared_calibration_error(pred_mean, pred_std, y)\n",
    "            ma = uct.miscalibration_area(pred_mean, pred_std, y)\n",
    "    \n",
    "            idx_counter += 1\n",
    "            ylims = [min(b), max(b)]\n",
    "            \n",
    "            # Calibration plot\n",
    "            plt.figure(figsize=(5, 5))\n",
    "            uct.plot_calibration(pred_mean, pred_std, y)\n",
    "            calibration_img_path = f\"results/img_new/O{n0+1}_row_{idx_counter}\"\n",
    "            uct.viz.save_figure(calibration_img_path, 'png', white_background=True)\n",
    "            plt.close()\n",
    "    \n",
    "            # Confidence interval plot\n",
    "            fig, ax = plt.subplots(figsize=(5, 5))\n",
    "            ci = 1.96  # Corresponds to 95% confidence interval\n",
    "            lower_bound = pred_mean - ci * pred_std\n",
    "            upper_bound = pred_mean + ci * pred_std\n",
    "            subset_size = 7 # Adjust as necessary to focus on a specific range\n",
    "            subset_indices = np.linspace(0, len(pred_mean) - 1, subset_size).astype(int)\n",
    "            ax.fill_between(subset_indices, lower_bound[subset_indices], upper_bound[subset_indices], color='b', alpha=0.2, label='95\\% Confidence Interval')\n",
    "            ax.plot(subset_indices, pred_mean[subset_indices], \n",
    "                    color='red', marker='o', linewidth=1, label='Mean of predicted values')\n",
    "            ax.plot(subset_indices, y[subset_indices], \n",
    "                    color='blue', marker='o', linewidth=1, label='Actual value')\n",
    "            ax.legend(loc=2)\n",
    "            plt.xlabel('Ordered Data Points')\n",
    "            plt.ylabel('Value')\n",
    "            plt.title('Predicted Mean with 95\\% Confidence Interval')\n",
    "            confidence_img_path = f\"results/img_new/N_O{n0+1}_row_{idx_counter}.png\"\n",
    "            plt.savefig(confidence_img_path, bbox_inches='tight', pad_inches=0.1)\n",
    "            plt.close(fig)\n",
    "            \n",
    "            # Load the images\n",
    "            img1 = Image.open(confidence_img_path)\n",
    "            img2 = Image.open(calibration_img_path + '.png')\n",
    "    \n",
    "            # Resize img2 to match the dimensions of img1\n",
    "            img2_resized = img2.resize((img1.width, img1.height))\n",
    "    \n",
    "            # Create a new image with the combined width and height\n",
    "            combined_width = img1.width + img2_resized.width\n",
    "            combined_height = img1.height  # Both images now have the same height\n",
    "    \n",
    "            combined_img = Image.new('RGB', (combined_width, combined_height), 'white')\n",
    "    \n",
    "            # Paste the images into the new image\n",
    "            combined_img.paste(img1, (0, 0))\n",
    "            combined_img.paste(img2_resized, (img1.width, 0))\n",
    "    \n",
    "            combined_img_path = f\"results/img_new/final/O{n0+1}_row_{idx_counter}.png\"\n",
    "            combined_img.save(combined_img_path)\n",
    "    \n",
    "            print(f\"Combined image saved at {combined_img_path}\")\n",
    "    \n",
    "      \n",
    "            v_MACE.append(round(mace,4))\n",
    "            v_RMSCE.append(round(rmsce,4))\n",
    "            v_MA.append(round(ma,4))\n",
    "            print(f\"MACE: {round(mace,4)}, RMSCE: {round(rmsce,4)}, MA: {round(ma,4)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-21T06:47:19.629040Z",
     "start_time": "2024-06-21T06:47:19.624668Z"
    }
   },
   "id": "d449c3cc954b424d",
   "execution_count": 410
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
